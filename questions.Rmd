```{r, libraries_question, include=FALSE}
library(tidyverse)
library(cowplot)
library(corrplot)
library(car)
library(FactoMineR)
library(lmtest)
library(xtable)
```

# Analysis

<!-- 1 -->
## Determine if the response variable (price) has an acceptably normal distribution. Address test to discard serial correlation.

```{r q1_price_hist, echo = FALSE, fig.height = 3}

df <- df %>% mutate(price_log = log(price))

price_mean <- mean(df$price)
price_sd <- sd(df$price)

ggplot(df, aes(price)) +
    geom_histogram(aes(y = ..density..), bins = 30) +
    stat_function(
        fun = dnorm,
        args = list(mean = price_mean, sd = price_sd),
        aes(color = "normal"),
    ) +
    geom_density(aes(color = "density"), linetype = "dashed") +
    geom_text(aes(
        x = max(df$price) * 3 / 4, y = 1e-5,
        color = "normal"
    ),
    label = sprintf(
        "μ = %0.2f\nσ = %0.2f",
        price_mean,
        price_sd
    ),
    show.legend = FALSE,
    ) +
    guides(color = guide_legend(title = NULL))
```

```{r q1_price_log_hist, echo = FALSE, fig.height = 3}

price_log_mean <- mean(df$price_log)
price_log_sd <- sd(df$price_log)

ggplot(df, aes(price_log)) +
    geom_histogram(aes(y = ..density..), bins = 30) +
    stat_function(
        fun = dnorm,
        args = list(mean = price_log_mean, sd = price_log_sd),
        aes(color = "normal")
    ) +
    geom_density(aes(color = "density"), linetype = "dashed") +
    geom_text(aes(
        x = 11, y = 0.75,
        color = "normal"
    ),
    label = sprintf(
        "μ = %0.2f\nσ = %0.2f",
        price_log_mean,
        price_log_sd
    ),
    show.legend = FALSE,
    ) +
    guides(color = guide_legend(title = NULL))
```

```{r q1_shapiro}
shapiro.test(df$price)
shapiro.test(log(df$price))
```

\Cref{fig:q1_qq_plots} shows the QQ plots.

```{r q1_qq_plots, echo=FALSE, fig.cap="QQ plots", fig.width=6}
plt_qq_price <- ggplot(df, aes(sample = price)) +
    stat_qq() +
    stat_qq_line(color = "red") +
    theme(aspect.ratio = 1) +
    labs(x = "Theoretical", y = "price")
plt_qq_log_price <- ggplot(df, aes(sample = log(price))) +
    stat_qq() +
    stat_qq_line(color = "red") +
    theme(aspect.ratio = 1) +
    labs(x = "Theoretical", y = "log(price)")

plot_grid(plt_qq_price, plt_qq_log_price, align = "hv", labels = "AUTO")
```

```{r q1_Kolmogorov-Smirnov}
df$price %>% ks.test("pnorm", mean = mean(.), sd = sd(.))
df$price_log %>% ks.test("pnorm", mean = mean(.), sd = sd(.))
```

```{r}
dwtest_res <- dwtest(price ~ 1, data = df)
```

We perform a Durbin-Watson test with the null hypothesis that the
autocorrelation of the disturbances is 0. We obtain a *p-value* of
`r round(dwtest_res$p.value, 2)` so we fail to reject the null hypothesis.

```{r}
dwtest_res
```

The results of the test are consistent with the visual interpretation of
the ACF plot^[lag 0 is omitted for clarity] shown in \cref{fig:acf}.
All the values except lag = 33 lie within the confidence interval of 95%,
showing that there is no autocorrelation.

```{r acf, fig.cap = "ACF plot for price"}
acf_res <- acf(df$price, plot = FALSE)
acf_res_df <- with(acf_res, data.frame(lag, acf)) %>%
    slice(-1) # Remove lag 0

# Confidence interval
acf_ci <- function(acf_res, alpha = 0.05) {
    return(qnorm((1 + (1 - alpha)) / 2) / sqrt(acf_res$n.used))
}

conf_inter <- acf_ci(acf_res, 0.05)

ggplot(data = acf_res_df, mapping = aes(x = lag, y = acf)) +
    geom_hline(aes(yintercept = 0)) +
    geom_segment(mapping = aes(xend = lag, yend = 0)) +
    geom_hline(aes(yintercept = conf_inter), linetype = "dashed", color = "blue") +
    geom_hline(aes(yintercept = -conf_inter), linetype = "dashed", color = "blue") +
    labs(x = "Lag", y = "ACF")
```

<!-- 2. --> \pagebreak
## Indicate by exploration of the data, which are apparently the variables most associated with the response variable (use only the indicated variables).

```{r q2_corrplot, fig.cap = "Spearman correlation plot", fig.height = 2.5}
cor_mat <- df %>%
    select(where(is.numeric), -price_log) %>%
    cor(use = "complete.obs", method = "spearman")

cor_mat %>% corrplot()
```

```{r q2_corr}
cor_mat %>%
    kable(
        caption = "Spearman correlation coefficients",
        booktabs = TRUE,
        digits = 2
    ) %>%
    kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)
```

```{r q2_factors}
df_cond <- df %>%
    select(-c(model, aux_price)) %>%
    condes(which(colnames(.) == "price_log"))

df_cond$quali %>%
    data.frame() %>%
    rownames_to_column("Variable") %>%
    select(-p.value) %>%
    kable(
        caption = "Qualitative variable correlation with log(price)",
        booktabs = TRUE,
        digits = 2
    ) %>%
    kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)
```

```{r q2_factors_cat}
df_cond$category %>%
    data.frame() %>%
    arrange(desc(abs(Estimate))) %>%
    rownames_to_column("Variable") %>%
    kable(
        caption = "Qualitative categories correlation with log(price)",
        booktabs = TRUE,
        digits = 2
    ) %>%
    kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)
```

<!-- 3. --> \pagebreak
## Define a polytomic factor f.age for the covariate car age according to its quartiles, and argue if the average price depends on the level of age.  Statistically justify the answer.

```{r q3_bp}
df %>%
    ggplot(aes(x = aux_age, y = price, fill = aux_age)) +
    geom_boxplot()

anova <- aov(price ~ aux_age, data = df)
summary(anova)
TukeyHSD(anova)

# Check anova assumptions
# Homogenity of variance
plot(anova, 1)
leveneTest(price ~ aux_age, data = df)
bartlett.test(price ~ aux_age, data = df)

# Normality assumption
plot(anova, 2)
shapiro.test(residuals(anova))
```


<!-- 4. --> \pagebreak
## Calculate and interpret the anova model that explains car price according to the age factor and the fuel type.

```{r q4}
df %>%
    ggplot(aes(x = aux_age, y = price, fill = fuelType)) +
    geom_boxplot()

anova <- aov(price ~ aux_age * fuelType, data = df)
summary(anova)

group_by(df, aux_age, fuelType) %>%
    summarise(
        count = n(),
        mean = mean(price, na.rm = TRUE),
        sd = sd(price, na.rm = TRUE)
    )
```

<!-- 5. --> \pagebreak
## Do you think that the variability of the price depends on both factors? Does the relation between price and age factor depend on fuel type?

```{r}
summary(anova)
```

<!-- 6. --> \pagebreak
## Calculate the linear regression model that explains the price from the age: interpret the regression line and assess its quality.

```{r q6, fig.height = 4, fig.width=6}

lm_tibble <- function(lm_model) {
    summary_lm <- summary(lm_model)
    with(summary_lm, tribble(
        ~statistic, ~value,
        "Residual standard error", sigma,
        "Degrees of freedom", df,
        "Multiple R-squared", r.squared,
        "Adjusted R-squared", adj.r.squared,
        "F-statistic", fstatistic,
    ))
}

model <- lm(price ~ age, data = df)
model %>%
    xtable() %>%
    kable(
        caption = "Linear regression on price $\\sim$ age",
        booktabs = TRUE,
        digits = 2
    ) %>%
    kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)

lm_tibble(model) %>%
    kable(
        caption = "Linear regression on price $\\sim$ age statistics",
        booktabs = TRUE,
        digits = 2
    ) %>%
    kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)

df %>%
    ggplot(aes(age, price)) +
    geom_boxplot(aes(group = age)) +
    geom_smooth(method = "lm") +
    labs(title = paste(
        "Adj R2 = ", signif(summary(model)$adj.r.squared, 5),
        "Intercept =", signif(model$coef[[1]], 5),
        " Slope =", signif(model$coef[[2]], 5),
        " P =", signif(summary(model)$coef[2, 4], 5)
    ))
```

```{r q6_resid}
qplot(seq(1, length(model$residuals)), model$residuals, geom = "point") +
    geom_hline(aes(yintercept = 0), color = "red")
```

```{r q6_log, fig.height = 4, fig.width=6}

model_log <- lm(price_log ~ age, data = df)
model_log %>%
    xtable() %>%
    kable(
        caption = "Linear regression on log(price) $\\sim$ age ",
        booktabs = TRUE,
        digits = 2
    ) %>%
    kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)

lm_tibble(model_log) %>%
    kable(
        caption = "Linear regression on log(price) $\\sim$ age statistics",
        booktabs = TRUE,
        digits = 2
    ) %>%
    kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)

df %>%
    ggplot(aes(age, price_log)) +
    geom_boxplot(aes(group = age)) +
    geom_smooth(method = "lm") +
    labs(title = paste(
        "Adj R2 = ", signif(summary(model_log)$adj.r.squared, 5),
        "Intercept =", signif(model_log$coef[[1]], 5),
        " Slope =", signif(model_log$coef[[2]], 5),
        " P =", signif(summary(model_log)$coef[2, 4], 5)
    ))
```

```{r q6_resid_log}
qplot(seq(1, length(model_log$residuals)), model_log$residuals, geom = "point") +
    geom_hline(aes(yintercept = 0), color = "red")
```



<!-- 7. --> \pagebreak
## What is the percentage of the price variability that is explained by the age of the car?

```{r}
summary(model)
```


<!-- 8. --> \pagebreak
## Do you think it is necessary to introduce a quadratic term in the equation that relates the price to its age?

```{r}
lm_mileage <- lm(price ~ age + I(age^2), df)
plot(lm_mileage)
```


<!-- 9. --> \pagebreak
## Are there any additional explanatory numeric variables needed to the car price? Study collinearity effects.

```{r}
lm <- lm(price ~ ., data = select(df, where(is.numeric)))
summary(lm)

# Collinearity
df %>%
    select(where(is.numeric)) %>%
    cor(use = "complete.obs") %>%
    corrplot()

lm_mileage <- lm(mileage ~ . - price, select(df, where(is.numeric)))
summary(lm_mileage)
lm_tax <- lm(tax ~ . - price, select(df, where(is.numeric)))
summary(lm_tax)
lm_mpg <- lm(mpg ~ . - price, select(df, where(is.numeric)))
summary(lm_mpg)
lm_age <- lm(age ~ . - price, select(df, where(is.numeric)))
summary(lm_age)
```


<!-- 10. --> \pagebreak
## After controlling by numerical variables, indicate whether the additive effect of the available factors on the price are statistically significant.

<!-- 11. --> \pagebreak
## Select the best model available so far. Interpret the equations that relate the explanatory variables to the answer (rate).

<!-- 12. --> \pagebreak
## Study the model that relates the logarithm of the price to the numerical variables.

```{r}
lm <- lm(price_log ~ ., data = select(df, where(is.numeric)))
summary(lm)
plot(lm)
```


<!-- 13. --> \pagebreak
## Once explanatory numerical variables are included in the model, are there any main effects from factors needed?

<!-- 14. --> \pagebreak
## Graphically assess the best model obtained so far.

<!-- 15. --> \pagebreak
## Assess the presence of outliers in the studentized residuals at a 99% confidence level. Indicate what those observations are.

<!-- 16. --> \pagebreak
## Study the presence of a priori influential data observations, indicating their number according to the criteria studied in class.

<!-- 17. --> \pagebreak
## Study the presence of a posteriori influential values, indicating the criteria studied in class and the actual atypical observations.

<!-- 18. --> \pagebreak
## Given a 5-year-old car, the rest of numerical variables on the mean and factors on the reference

<!-- 19. --> \pagebreak
## Summarize what you have learned by working with this interesting real dataset.
